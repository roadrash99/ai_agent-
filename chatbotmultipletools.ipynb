{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv,description=\"Query arxiv papers\")\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-07-22\\nTitle: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\\nAuthors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\\nSummary: The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time o\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.invoke(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_wikipedia = WikipediaAPIWrapper(top_k_results=2, doc_content_chars_max=500)\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper_wikipedia, description=\"Query Wikipedia articles\")\n",
    "print(wikipedia.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Artificial Intelligence News - ScienceDaily',\n",
       "  'url': 'https://www.sciencedaily.com/news/computers_math/artificial_intelligence/',\n",
       "  'content': \"Tuesday, November 12, 2024\\n\\nGiving Robots Superhuman Vision Using Radio Signals\\n\\nMonday, November 11, 2024\\n\\nAI Can Detect Serious Neurologic Changes in Babies in the NICU Using Video Data Alone\\nRobot That Watched Surgery Videos Performs With Skill of Human Doctor, Researchers Report\\n\\nThursday, November 7, 2024\\n\\nRobot Learns How to Clean a Washbasin\\n\\nWednesday, November 6, 2024\\n\\nAI-Driven Mobile Robots Team Up to Tackle Chemical Synthesis\\n\\nThursday, October 31, 2024 [...] Using Robots in Nursing Homes Linked to Higher Employee Retention, Better Patient Care\\n\\nMonday, January 6, 2025\\n\\nAI Slashes Cost and Time for Chip Design, but That Is Not All\\n\\nThursday, January 2, 2025\\n\\nArtificial Intelligence: Algorithms Improve Medical Image Analysis\\n\\nFriday, December 27, 2024\\n\\nCrossing the Uncanny Valley: Breakthrough in Technology for Lifelike Facial Expressions in Androids\\n\\nThursday, December 26, 2024\\n\\nWind Sensing by Biomimetic Flexible Flapping Wing With Strain Sensors [...] Thursday, December 19, 2024\\n\\nMachine Psychology: A Bridge to General AI?\\nLaser-Based Artificial Neuron Mimics Nerve Cell Functions at Lightning Speed\\n\\nWednesday, December 18, 2024\\n\\nSwarms of 'ant-Like' Robots Lift Heavy Objects and Hurl Themselves Over Obstacles\\n\\nTuesday, December 17, 2024\\n\\nDeveloping Artificial Intelligence Tools for Health Care\\nTiny Robots, Big Impact: Revolutionizing Infertility Treatment With Magnetic Microrobots\\n\\nMonday, December 16, 2024\",\n",
       "  'score': 0.75290436},\n",
       " {'title': 'AI News | Latest AI News, Analysis & Events',\n",
       "  'url': 'https://www.artificialintelligence-news.com/',\n",
       "  'content': 'Applications, Artificial Intelligence, Companies, DeepMind, Google, Industries\\nApril 14, 2025\\nIEA: The opportunities and challenges of AI for global energy\\nApplications, Artificial Intelligence, Energy, Ethics & Society, Industries, Research\\nApril 10, 2025\\nSpot AI introduces the world’s first universal AI agent builder for security cameras\\nApplications, Artificial Intelligence, Healthcare, Security\\nApril 10, 2025\\nDeep Learning\\nAlibaba Qwen QwQ-32B: Scaled reinforcement learning showcase [...] Marketing Tech News\\nApril 16, 2025\\nOpenAI explores social platform following $40B funding round\\n\\nAI News\\nApril 15, 2025\\nMeta will train AI models using EU user data\\n\\nDeveloper Tech News\\nApril 15, 2025\\nMasquerading payment npm package installs backdoor\\n\\nTelecoms Tech News\\nApril 15, 2025\\nFCC chair calls EU satellite strategy ‘anti-American’\\nSubscribe\\nAll our premium content and latest tech news delivered straight to your inbox\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\nExplore [...] Artificial Intelligence, Companies, Deep & Reinforcement Learning, Development\\nMarch 6, 2025\\nDeepSeek-R1 reasoning models rival OpenAI in performance\\nArtificial Intelligence, Companies, Deep & Reinforcement Learning, Development\\nJanuary 20, 2025\\nNew AI training techniques aim to overcome current challenges\\nDeep & Reinforcement Learning, Machine Learning, NVIDIA, Research\\nNovember 28, 2024',\n",
       "  'score': 0.7413937},\n",
       " {'title': 'AI News & Artificial Intelligence - TechCrunch',\n",
       "  'url': 'https://techcrunch.com/category/artificial-intelligence/',\n",
       "  'content': '1 day ago\\n\\n\\n\\nAI\\nOpenAI hires team behind GV-backed AI eval platform Context.ai\\n\\nIvan Mehta\\n\\n1 day ago\\n\\n\\n\\nAI\\nAnthropic forms a new team to grow its AWS business\\n\\nKyle Wiggers\\n\\n2 days ago\\n\\n\\n\\nAI\\nAnthropic’s Claude can now read your Gmail\\n\\nMaxwell Zeff\\n\\n2 days ago\\n\\n\\n\\nAI\\nGoogle’s Veo 2 video generating model comes to Gemini\\n\\nKyle Wiggers\\n\\n2 days ago\\n\\n\\n\\nAI\\nWitness a dynamic dialogue between two visionary CEOs\\n\\nCindy Zackney\\n\\n2 days ago\\n\\n\\n\\nIn Brief [...] AI\\nGrok gains a canvas-like tool for creating docs and apps\\n\\nKyle Wiggers\\n\\n1 day ago\\n\\n\\n\\nEnterprise\\nNvidia H20 chip exports hit with license requirement by US government\\n\\nRebecca Szkutak\\n\\n1 day ago\\n\\n\\n\\nFundraising\\nTelli, a YC alum, raises pre-seed funding for its AI voice agents\\n\\nMike Butcher\\n\\n1 day ago\\n\\n\\n\\nAI\\nOpenAI may ‘adjust’ its safeguards if rivals release ‘high-risk’ AI\\n\\nKyle Wiggers\\n\\n1 day ago\\n\\n\\n\\nStartups\\nFigma sent a cease-and-desist letter to Lovable over the term ‘Dev Mode’\\n\\nJulie Bort [...] AI\\nOpenAI partner says it had relatively little time to test the company’s o3 AI model\\n\\nKyle Wiggers\\n\\n12 hours ago\\n\\n\\n\\nAI\\nOpenAI launches a pair of AI reasoning models, o3 and o4-mini\\n\\nMaxwell Zeff\\n\\n13 hours ago\\n\\n\\n\\nAI\\nOpenAI debuts Codex CLI, an open source coding tool for terminals\\n\\nKyle Wiggers\\n\\n13 hours ago\\n\\n\\n\\nVenture\\nStartup funding hit records in Q1. But the outlook for 2025 is still awful.\\n\\nMarina Temkin\\n\\n14 hours ago',\n",
       "  'score': 0.7230167}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"Provide me the recent AI news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[arxiv,wikipedia,tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"qwen-qwq-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user is asking, \"What is AI?\" Let me start by breaking down what they might need. They could be a beginner looking for a simple explanation or someone with some background wanting a deeper dive. I should cover the basics first.\\n\\nAI stands for Artificial Intelligence. I should define it in simple terms, maybe compare it to human intelligence. Then mention the key areas like machine learning, deep learning, and neural networks. Wait, but how detailed should I get? The user might not know those terms yet, so I need to explain them briefly.\\n\\nAlso, applications are important. Examples like Siri, self-driving cars, recommendation systems. That makes it relatable. Maybe touch on types of AI: narrow vs general AI. Oh, right, there\\'s also the difference between weak and strong AI. Should clarify that.\\n\\nI should also mention how AI works, maybe talk about data processing and algorithms. Not too technical, but enough to give an idea. Maybe a sentence on machine learning being a subset of AI. Wait, actually, machine learning is a subset, and deep learning is a subset of ML. Need to get that hierarchy right.\\n\\nEthical considerations are becoming a big part of AI discussions. So, including things like bias, privacy, job impact could be useful. The user might be interested in the broader implications, not just the technical side.\\n\\nI should structure the answer step by step. Start with a definition, then key concepts, applications, types, how it works, and then the ethical aspects. Keep it clear and avoid jargon as much as possible. Maybe use bullet points or sections for clarity, but since the user might want a natural paragraph, I\\'ll need to flow it smoothly.\\n\\nWait, let me check if I\\'m missing anything. History? Maybe a quick mention of early developments, but maybe that\\'s too much. The user just asked for \"what is AI,\" so focus on the present understanding. Okay, maybe a brief mention of origins but not too deep.\\n\\nAlso, differentiation between AI and automation? Hmm, maybe not necessary unless the user is confused between the two. Since the question is straightforward, maybe stick to defining AI.\\n\\nMake sure to highlight that AI involves mimicking human cognitive functions like learning and problem-solving. Emphasize that it\\'s a field of computer science. Alright, that should cover the main points. Let me put it all together in a coherent way without making it too long.\\n</think>\\n\\n**Artificial Intelligence (AI)** refers to the simulation of human intelligence in machines to perform tasks that typically require human cognition, such as learning, reasoning, problem-solving, perception, and decision-making. It is a branch of computer science focused on creating systems that can perform tasks that usually demand human-like intelligence. Here\\'s a breakdown of key aspects:\\n\\n### 1. **Core Concepts**:\\n   - **Machine Learning (ML)**: A subset of AI where systems learn from data to improve performance on specific tasks without explicit programming (e.g., predicting stock prices).\\n   - **Deep Learning**: A specialized type of ML using **artificial neural networks** (modeled after the human brain) to analyze vast datasets (e.g., facial recognition).\\n   - **Natural Language Processing (NLP)**: Enables machines to understand, interpret, and generate human language (e.g., chatbots, translation apps).\\n\\n### 2. **Types of AI**:\\n   - **Narrow (Weak) AI**: Designed for specific tasks (e.g., Siri answering questions, recommendation algorithms on Netflix).\\n   - **General (Strong) AI**: Hypothetical systems with human-level intelligence, capable of solving *any* intellectual task (not yet achieved).\\n\\n### 3. **Applications**:\\n   - **Healthcare**: Diagnosing diseases, drug discovery, and personalized treatment plans.\\n   - **Autonomous Systems**: Self-driving cars and drones.\\n   - **Finance**: Fraud detection, algorithmic trading.\\n   - **Daily Tech**: Smart assistants (Alexa), spam filters, and image recognition software.\\n\\n### 4. **How It Works**:\\n   - **Data-Driven**: Relies on large datasets to train models and identify patterns.\\n   - **Algorithms**: Step-by-step procedures that enable machines to \"learn\" or make decisions.\\n   - **Feedback Loops**: Systems improve over time through iterative learning.\\n\\n### 5. **Ethical and Societal Considerations**:\\n   - **Bias**: ML models can inherit biases from training data (e.g., racial/gender discrimination).\\n   - **Privacy**: Risks of data misuse in facial recognition or surveillance.\\n   - **Job Impact**: Automation may disrupt industries, requiring workforce adaptation.\\n   - **Safety**: Ensuring AI systems (e.g., autonomous weapons) are aligned with human values.\\n\\n### 6. **History & Evolution**:\\n   - Emerged in the 1950s, but recent advancements in computing power, big data, and neural networks have driven breakthroughs (e.g., AlphaGo, ChatGPT).\\n\\n### Key Takeaway:\\nAI is not \"intelligence\" in the human sense but a tool that enhances human capabilities. It is reshaping industries while prompting debates about ethics, responsibility, and societal impact. As AI evolves, its potential to solve complex problems grows, but so do the challenges it poses.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1084, 'prompt_tokens': 13, 'total_tokens': 1097, 'completion_time': 2.649647096, 'prompt_time': 0.002893175, 'queue_time': 0.050619693, 'total_time': 2.652540271}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_fbb7e6cc39', 'finish_reason': 'stop', 'logprobs': None}, id='run-11b38aca-6e33-4070-a08f-106f2bde3603-0', usage_metadata={'input_tokens': 13, 'output_tokens': 1084, 'total_tokens': 1097})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_te1m', 'function': {'arguments': '{\"query\": \"recent AI news\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_8bye', 'function': {'arguments': '{\"query\": \"AI\"}', 'name': 'arxiv'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 347, 'prompt_tokens': 333, 'total_tokens': 680, 'completion_time': 0.860014714, 'prompt_time': 0.018920881, 'queue_time': 0.018809379, 'total_time': 0.878935595}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1d56dd0f-a13d-40eb-94ff-c048da3fbe7d-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'recent AI news'}, 'id': 'call_te1m', 'type': 'tool_call'}, {'name': 'arxiv', 'args': {'query': 'AI'}, 'id': 'call_8bye', 'type': 'tool_call'}], usage_metadata={'input_tokens': 333, 'output_tokens': 347, 'total_tokens': 680})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"What is AI? Provide me the recent AI news and some arxiv papers about it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import  AnyMessage\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,Image\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_calling_llm(state:State):\n",
    "    return{\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "    \n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START,\"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "1706.03672\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_6amt)\n",
      " Call ID: call_6amt\n",
      "  Args:\n",
      "    query: 1706.03672\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2017-06-12\n",
      "Title: Determination of the NNLO low-energy constant $C_{93}$\n",
      "Authors: Maarten Golterman, Kim Maltman, Santiago Peris\n",
      "Summary: Experimental data from hadronic $\\tau$ decays allow for a precision\n",
      "determination of the slope of the $I=1$ vacuum polarization at zero momentum.\n",
      "We use this information to provide a value for the next-to-next-to-leading\n",
      "order (NNLO) low-energy constant $C_{93}$ in chiral perturbation theory. The\n",
      "largest systematic error in this determination result\n"
     ]
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":\"1706.03672\"})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi my name is Dhoni\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Dhoni! Nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":\"Hi my name is Dhoni\"})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
